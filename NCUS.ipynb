{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7da373-3f60-4238-b857-38719b265c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymystem3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mystem\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "import tensorflow as tf\n",
    "import pickle \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pyttsx3\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig, pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2c08f-3976-48f7-ab23-2b77bca826ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09385a18-d7d0-486c-a07f-1a6e478d2782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a5a4e3-a4c6-4b49-b0d8-fe446f67f9ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiberiaSoft/SiberianFredT5-instructor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Настройки двигателя для озвучки текста\u001b[39;00m\n\u001b[0;32m      4\u001b[0m engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=\"SiberiaSoft/SiberianFredT5-instructor\")\n",
    "\n",
    "#Настройки двигателя для озвучки текста\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('rate', 200) \n",
    "engine.setProperty('voice', voices[2].id)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SiberiaSoft/SiberianFredT5-instructor\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"SiberiaSoft/SiberianFredT5-instructor\")\n",
    "model.eval()\n",
    "emot_model = tf.keras.models.load_model('model_classifire.keras')\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "        token = pickle.load(handle)\n",
    "\n",
    "def generate(prompt):\n",
    "  data = tokenizer('<SC6>' + prompt + '\\nОтвет: <extra_id_0>', return_tensors=\"pt\")\n",
    "  data = {k: v.to(model.device) for k, v in data.items()}\n",
    "  output_ids = model.generate(\n",
    "      **data,  do_sample=True, temperature=0.2, max_new_tokens=512, top_p=0.95, top_k=5, repetition_penalty=1.03, no_repeat_ngram_size=2\n",
    "  )[0]\n",
    "  out = tokenizer.decode(output_ids.tolist())\n",
    "  out = out.replace(\"<s>\",\"\").replace(\"</s>\",\"\")\n",
    "  return out\n",
    "\n",
    "def lemmatiz(text, lst):\n",
    "    m = Mystem()\n",
    "    lemmas = m.lemmatize(text)\n",
    "    lst.append(\"\".join(lemmas))\n",
    "\n",
    "def emotion_animaton(emotion):\n",
    "    if emotion == 0:\n",
    "        print(\"This text haven't any emotion\")\n",
    "    elif emotion == 1:\n",
    "        keyboard.send(\"num 2\")\n",
    "    elif emotion == 2:\n",
    "        keyboard.send(\"num 1\")\n",
    "    elif emotion == 3:\n",
    "        keyboard.send(\"num 3\")\n",
    "    elif emotion == 4:\n",
    "        keyboard.send(\"num 5\")\n",
    "    elif emotion == 5:\n",
    "        keyboard.send(\"num 4\")\n",
    "    else:\n",
    "        print(\"Error: Emotion not register\")\n",
    "\n",
    "while 1:\n",
    "    neuro_answ = (generate(input(\"Введите промпт и фразу: \")))\n",
    "    time.sleep(3)\n",
    "    user_list = []\n",
    "\n",
    "    #пред-обработка данных для прогнозирования эмоции\n",
    "    lemmatiz(neuro_answ[17:], user_list)\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = word_tokenize(user_list[0].replace(\"'\", \"\").replace(\"\\n\", \"\"), 'russian')\n",
    "    clear_user_input = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            clear_user_input.append(word)\n",
    "    user_x = token.texts_to_sequences(clear_user_input)\n",
    "    user_x = pad_sequences(user_x, maxlen=15690, padding='post', truncating='post')\n",
    "    user_x = token.texts_to_matrix([clear_user_input])\n",
    "\n",
    "    #Прогназирование эмоции\n",
    "    y_pred = emot_model.predict(user_x)\n",
    "    Emotion = np.where(y_pred[0] == y_pred.max())[0][0]\n",
    "    emotion_animaton(Emotion)\n",
    "\n",
    "    \n",
    "    #Озвучивание ответа\n",
    "    engine.say(neuro_answ[17:])\n",
    "    engine.runAndWait()\n",
    "    print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ee5829-2dc0-4bc9-8292-24cedd0ba9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Введите текст \n",
      " мяу\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "import tensorflow as tf\n",
    "import pickle \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "clear_user_input = []\n",
    "user_list = []\n",
    "user_input = input(\"Введите текст \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270008a3-e14e-4273-bb2b-58d56c6b30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9dac50-192c-4956-9537-c3b1e5f8a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step\n"
     ]
    }
   ],
   "source": [
    "def lemmatiz(text, lst):\n",
    "    m = Mystem()\n",
    "    lemmas = m.lemmatize(text)\n",
    "    lst.append(\"\".join(lemmas))\n",
    "\n",
    "\n",
    "#model = tf.keras.models.load_model('model_classifire.keras')\n",
    "lemmatiz(user_input, user_list)\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    token = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "tokens = word_tokenize(user_list[0].replace(\"'\", \"\").replace(\"\\n\", \"\"), 'russian')\n",
    "for word in tokens:\n",
    "    if word not in stop_words:\n",
    "        clear_user_input.append(word)\n",
    "user_x = token.texts_to_sequences(clear_user_input)\n",
    "user_x = pad_sequences(user_x, maxlen=15690, padding='post', truncating='post')\n",
    "user_x = token.texts_to_matrix([clear_user_input])\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('model_classifire.keras')\n",
    "y_pred = model.predict(user_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24865202-0b2b-4d25-a751-a531a81f1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.where(y_pred[0] == y_pred.max())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3594a8c-4885-4697-9b64-fbbd47d7199e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(g)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164b89bb-e7db-429e-a0f5-09daf33c3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac28f0-57d5-4944-9691-a3d2c575f6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf1caeb-cdaa-4cdb-9afb-51d03dd3c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40283a3b-3f53-45b7-8548-fda6e5544e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key = [\"отсутствует\", \"радость\", \"печаль/грусть\", \"удивление\", \"страх\", \"гнев/злость\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7b3771-8a48-4d7b-ab0e-16cc4704c020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'удивление'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_key[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503e1593-cff1-481e-9342-728c57bb3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"<pad><extra_id_0>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217a58e5-bfc2-41e5-af42-ece984db1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcfd651-7d72-4233-aad7-d9f2ae07cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "keyboard.send(\"num 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f334628-1480-45f7-bf24-d70624b648b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_animaton(emotion):\n",
    "    if emotion == 0:\n",
    "        print(\"This text haven't any emotion\")\n",
    "    elif emotion == 1:\n",
    "        keyboard.send(\"num 2\")\n",
    "    elif emotion == 2:\n",
    "        keyboard.send(\"num 1\")\n",
    "    elif emotion == 3:\n",
    "        keyboard.send(\"num 3\")\n",
    "    elif emotion == 4:\n",
    "        keyboard.send(\"num 5\")\n",
    "    elif emotion == 5:\n",
    "        keyboard.send(\"num 4\")\n",
    "    else:\n",
    "        print(\"Error: Emotion not register\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0dd6ed2c-fbc5-4c61-8df0-9a5e6e933cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86ff4319-7ac8-42e7-b17c-98da4cc87c4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fff\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fff' is not defined"
     ]
    }
   ],
   "source": [
    "fff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71b90d9b-fe66-4f43-b5d7-1ff53bd9a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2742f58b-8230-40f9-9d2a-b5c8f4c978ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "keyboard.send(\"num 2\")\n",
    "pyautogui.press(\"num2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee0a02-d684-4b0e-8330-efc1c9c7f03d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79876d3d-fbda-4724-99e5-e7211ae3666d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9046fdb-beb0-48e0-8a6e-504bf4fd9045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef26b0b-0db9-464c-a0f5-56ebd362a0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc08eb-b532-4d0e-ba9c-7b8a874a7769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b547ed-3267-4ebb-8908-3b14e569db2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ceca19-6a8c-4990-aab6-a328bdc0bb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553d69e-1f46-4f6b-abbb-3849e3cb8818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274390ce-46bc-4a50-be04-7e8a8f933a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f96ca9-9425-4a6e-b8ea-f7a5dd618af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba42e91-1949-4838-aa64-db7d00da3d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db53cf-8963-485e-ae89-f5a759fc713a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e38c27-e7b5-4fe7-b72c-2be12dcfd528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905daf1-804c-4c86-919b-d8a82aced94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6960029-d644-4e5c-ba5c-15ef18ff7bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023d6c7-c085-4179-8bc0-db7a4183761e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2420d2-4aa2-4d13-8b01-5dbd768efb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c653ce1-f074-4ada-97c7-fa1c442f8191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6441f6-6957-4e17-84ba-4a515976a19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772af0c-22e6-4954-b042-a981a7492fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff443a-3f3a-410d-8785-3ad845e11dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5cc439-90bc-4493-ad5e-afb9850a4d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f09695-f61b-4c89-a2d1-b1189b0137d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90bd6e42-c84a-4c41-99fd-aa1b050c930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, pyvts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "796f83ae-d400-4f77-9d9f-33a7ad7312c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin_info = {\n",
    "    \"plugin_name\": \"start pyvts\",\n",
    "    \"developer\": \"Genteki\",\n",
    "    \"authentication_token_path\": \"0x000002AAA12CA340\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc24ca9-2b71-403c-a4e1-fa6866625e14",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['Without_Emotion', 'Happy', 'Sad', 'surprise', 'fear', 'Angry']\n"
     ]
    }
   ],
   "source": [
    "plugin_info = {\n",
    "    \"plugin_name\": \"trigger hotkey\",\n",
    "    \"developer\": \"OverHome\",\n",
    "    \"authentication_token_path\": \"./pyvts_token.txt\"\n",
    "}\n",
    "\n",
    "async def main():\n",
    "    myvts = pyvts.vts(plugin_info=plugin_info)\n",
    "    await myvts.connect()\n",
    "    await myvts.request_authenticate_token()  # get token\n",
    "    await myvts.request_authenticate()  # use token\n",
    "    response_data = await myvts.request(myvts.vts_request.requestHotKeyList())\n",
    "    hotkey_list = []\n",
    "    for hotkey in response_data['data']['availableHotkeys']:\n",
    "        hotkey_list.append(hotkey['name'])\n",
    "    print(hotkey_list) # ['My Animation 1', 'My Animation 2', ...]\n",
    "    send_hotkey_request = myvts.vts_request.requestTriggerHotKey(hotkey_list[0])\n",
    "    await myvts.request(send_hotkey_request) # send request to play 'My Animation 1'\n",
    "    await myvts.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop.create_task(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6e7480-bbcd-46c5-a99f-7c45449a013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b56fe7a6-3c38-46b3-adaf-7d2b202989fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-222' coro=<trigger() done, defined at C:\\Users\\skorp\\AppData\\Local\\Temp\\ipykernel_11868\\3178097241.py:11> exception=KeyError('authenticated')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\skorp\\AppData\\Local\\Temp\\ipykernel_11868\\3178097241.py\", line 14, in trigger\n",
      "    await myvts.request_authenticate()  # use token\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"G:\\anaconda\\Lib\\site-packages\\pyvts\\vts.py\", line 141, in request_authenticate\n",
      "    assert responese_dict[\"data\"][\"authenticated\"], \"Authentication Failed\"\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'authenticated'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import pyvts\n",
    "import asyncio\n",
    "\n",
    "async def connect_auth(myvts):\n",
    "    ''' functions to get authenticated '''\n",
    "    await myvts.connect()\n",
    "    await myvts.request_authenticate_token()\n",
    "    await myvts.request_authenticate()\n",
    "    await myvts.close()\n",
    "\n",
    "async def trigger(myvts):\n",
    "    ''' function to trigger hotkey '''\n",
    "    await myvts.connect()\n",
    "    await myvts.request_authenticate()  # use token\n",
    "    hotkey_list = ['Печаль/Грусть', 'Радость', 'Удивление', 'Angry', 'fear']\n",
    "    send_hotkey_request = myvts.vts_request.requestTriggerHotKey(hotkey_list[2])\n",
    "    await myvts.request(send_hotkey_request) # send request to play 'My Animation 1'\n",
    "    await myvts.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ''' using different functions '''\n",
    "    myvts = pyvts.vts(plugin_info=plugin_info)\n",
    "    loop.create_task(connect_auth(myvts))\n",
    "    loop.create_task(trigger(myvts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8be2b-4cd0-46d6-969c-422834c6c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
